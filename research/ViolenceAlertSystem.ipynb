{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "import telepot\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from PIL import Image, ImageEnhance\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE_BUCKET = os.getenv('STORAGE_BUCKET')\n",
    "BOT_TOKEN = os.getenv('BOT_TOKEN')\n",
    "CHAT_ID = os.getenv('CHAT_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Firebase Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import storage\n",
    "\n",
    "cred = credentials.Certificate(\"firebaseKey.json\")\n",
    "firebase_admin.initialize_app(cred, {'storageBucket': STORAGE_BUCKET})  # Initialize once\n",
    "\n",
    "db = firestore.client() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alert System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MoBiLSTM_model = tf.keras.models.load_model(\"detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT, IMAGE_WIDTH = 64, 64\n",
    "SEQUENCE_LENGTH = 16\n",
    "CLASSES_LIST = [\"NonViolence\", \"Violence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    normalized_frame = resized_frame / 255\n",
    "    return normalized_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_enhance(frame):\n",
    "    # Convert OpenCV frame to PIL image\n",
    "    frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Enhance sharpness\n",
    "    curr_bri = ImageEnhance.Sharpness(frame_pil)\n",
    "    new_bri = 1.3\n",
    "    img_brightened = curr_bri.enhance(new_bri)\n",
    "\n",
    "    # Enhance color\n",
    "    curr_col = ImageEnhance.Color(img_brightened)\n",
    "    new_col = 1.5\n",
    "    img_col = curr_col.enhance(new_col)\n",
    "\n",
    "    # Save enhanced image\n",
    "    img_col.save(\"finalImage.jpg\")\n",
    "\n",
    "    return img_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time():\n",
    "  IST = pytz.timezone('Asia/Kolkata')\n",
    "  timeNow = datetime.now(IST)\n",
    "  return timeNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_faces(filename, result_list):\n",
    "    # load the image\n",
    "    data = plt.imread(filename)\n",
    "    # plot each face as a subplot\n",
    "    for i in range(len(result_list)):\n",
    "        # get coordinates\n",
    "        x1, y1, width, height = result_list[i]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # define subplot\n",
    "        plt.subplot(1, len(result_list), i+1)\n",
    "        plt.axis('off')\n",
    "        # plot face\n",
    "        plt.imshow(data[y1:y2, x1:x2])\n",
    "    # show the plot\n",
    "    plt.savefig(\"faces.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_webcam(SEQUENCE_LENGTH, confidence_threshold=0.90):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    bot = telepot.Bot(BOT_TOKEN)\n",
    "    frames_list = []\n",
    "    location = \"Sector 20, Noida\"\n",
    "    violence_image = 'finalImage.jpg'\n",
    "    face_image = 'faces.png'\n",
    "    no_of_detections, alert_sent = 0, 0\n",
    "    last_alert_time = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame\n",
    "        normalized_frame = preprocess_frame(frame)\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "        # Ensure we have enough frames for the sequence\n",
    "        if len(frames_list) == SEQUENCE_LENGTH:\n",
    "            # Perform prediction\n",
    "            predicted_labels_probabilities = MoBiLSTM_model.predict(np.expand_dims(frames_list, axis=0))[0]\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "            predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "            # Display the prediction\n",
    "            confidence = predicted_labels_probabilities[predicted_label]\n",
    "            print(f'Predicted: {predicted_class_name}\\nConfidence: {confidence}')\n",
    "\n",
    "            # Display \"Violence\" in red if confidence is above the threshold\n",
    "            if predicted_class_name == \"Violence\" and confidence > confidence_threshold:\n",
    "                cv2.putText(frame, \"Violence\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                no_of_detections += 1\n",
    "\n",
    "                if no_of_detections >= 20 and alert_sent == 0:\n",
    "                    current_time = get_time()\n",
    "                    img_enhance(frame)\n",
    "                    pixels = plt.imread(violence_image)\n",
    "                    detector = MTCNN()\n",
    "                    faces = detector.detect_faces(pixels)\n",
    "                    draw_faces(violence_image, faces)\n",
    "\n",
    "                    bot.sendMessage(CHAT_ID, f\"VIOLENCE ALERT!! \\n at location: {location} \\n time: {current_time}\")\n",
    "                    bot.sendPhoto(CHAT_ID, photo=open('finalImage.jpg', 'rb'))\n",
    "                    bot.sendMessage(CHAT_ID, \"Faces Obtained\")\n",
    "                    bot.sendPhoto(CHAT_ID, photo=open('faces.png', 'rb'))\n",
    "\n",
    "                    storage_client = storage.bucket()\n",
    "\n",
    "                    try:\n",
    "                        storage_client.blob(violence_image).upload_from_filename(violence_image)\n",
    "                        storage_client.blob(face_image).upload_from_filename(face_image)\n",
    "                    \n",
    "                        # Get download URLs for the uploaded images\n",
    "                        violence_image_url = storage_client.blob(violence_image).public_url\n",
    "                        face_image_url = storage_client.blob(face_image).public_url\n",
    "                    \n",
    "                        # Add data to Firestore with download URLs\n",
    "                        db.collection(location).add({\n",
    "                            'date': current_time,\n",
    "                            'image': violence_image_url,\n",
    "                            'faces': face_image_url\n",
    "                        })\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error uploading images to Firebase Storage: {e}\")\n",
    "\n",
    "                    finally:\n",
    "                        alert_sent = 1\n",
    "                        last_alert_time = time.time()\n",
    "\n",
    "            # Check if it's been 5 minutes since the last alert\n",
    "            if last_alert_time is not None and time.time() - last_alert_time >= 5 * 60:\n",
    "                alert_sent = 0\n",
    "\n",
    "            # Clear the frames list for the next sequence\n",
    "            frames_list = []\n",
    "\n",
    "        # Display the webcam feed\n",
    "        cv2.imshow('Violence Detector', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close the window outside the loop\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_webcam(SEQUENCE_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ML_Projects\\\\Violence-Reporter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PredictionConfig:\n",
    "    root_dir: Path\n",
    "    model_path: Path\n",
    "    classes_list:list\n",
    "    params_image_height:int\n",
    "    params_image_width:int\n",
    "    params_sequence_length:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from violenceReporter.constants import *\n",
    "from violenceReporter.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config=read_yaml(config_filepath)\n",
    "        self.params=read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_prediction_config(self) -> PredictionConfig:\n",
    "        config=self.config.model_prediction\n",
    "        create_directories([\n",
    "            Path(config.root_dir)\n",
    "        ])\n",
    "\n",
    "        eval_config = PredictionConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            model_path=Path(config.prediction_model_path),\n",
    "            classes_list=config.classes_list,\n",
    "            params_image_height=self.params.IMAGE_HEIGHT,\n",
    "            params_image_width=self.params.IMAGE_WIDTH,\n",
    "            params_sequence_length=self.params.SEQUENCE_LENGTH\n",
    "        )\n",
    "        return eval_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "import telepot\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from PIL import Image, ImageEnhance\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import storage\n",
    "from violenceReporter import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    def __init__(self, config: PredictionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def set_credentials(self):\n",
    "        load_dotenv()\n",
    "        self.STORAGE_BUCKET = os.getenv('STORAGE_BUCKET')\n",
    "        self.BOT_TOKEN = os.getenv('BOT_TOKEN')\n",
    "        self.CHAT_ID = os.getenv('CHAT_ID')\n",
    "\n",
    "\n",
    "    def preprocess_frame(self,frame):\n",
    "        resized_frame = cv2.resize(frame, (self.config.params_image_height, self.config.params_image_width))\n",
    "        normalized_frame = resized_frame / 255\n",
    "        return normalized_frame\n",
    "    \n",
    "    def img_enhance(self,frame):\n",
    "        # Convert OpenCV frame to PIL image\n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Enhance sharpness\n",
    "        curr_bri = ImageEnhance.Sharpness(frame_pil)\n",
    "        new_bri = 1.3\n",
    "        img_brightened = curr_bri.enhance(new_bri)\n",
    "\n",
    "        # Enhance color\n",
    "        curr_col = ImageEnhance.Color(img_brightened)\n",
    "        new_col = 1.5\n",
    "        img_col = curr_col.enhance(new_col)\n",
    "\n",
    "        # Save enhanced image\n",
    "        img_col.save(os.path.join(self.config.root_dir,\"finalImage.jpg\"))\n",
    "\n",
    "        return img_col\n",
    "\n",
    "    @staticmethod\n",
    "    def get_time():\n",
    "        IST = pytz.timezone('Asia/Kolkata')\n",
    "        timeNow = datetime.now(IST)\n",
    "        return timeNow\n",
    "    \n",
    "    def draw_faces(self,filename, result_list):\n",
    "        # load the image\n",
    "        data = plt.imread(filename)\n",
    "        # plot each face as a subplot\n",
    "        for i in range(len(result_list)):\n",
    "            # get coordinates\n",
    "            x1, y1, width, height = result_list[i]['box']\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            # define subplot\n",
    "            plt.subplot(1, len(result_list), i+1)\n",
    "            plt.axis('off')\n",
    "            # plot face\n",
    "            plt.imshow(data[y1:y2, x1:x2])\n",
    "        # show the plot\n",
    "        plt.savefig(os.path.join(self.config.root_dir,\"faces.png\"))\n",
    "    \n",
    "\n",
    "    def initialize_database(self):\n",
    "        try:\n",
    "            cred = credentials.Certificate(\"firebaseKey.json\")\n",
    "            firebase_admin.initialize_app(cred, {'storageBucket': self.STORAGE_BUCKET})  # Initialize once\n",
    "            self.db = firestore.client()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(f\"error occured : {e}\")\n",
    "\n",
    "    def predict_webcam(self,confidence_threshold=0.75):\n",
    "        SEQUENCE_LENGTH=self.config.params_sequence_length\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        bot = telepot.Bot(self.BOT_TOKEN)\n",
    "        frames_list = []\n",
    "        location = \"Sector 20, Noida\"\n",
    "        violence_image = os.path.join(self.config.root_dir,\"finalImage.jpg\")\n",
    "        face_image = os.path.join(self.config.root_dir,\"faces.png\")\n",
    "        no_of_detections, alert_sent = 0, 0\n",
    "        last_alert_time = None\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Preprocess the frame\n",
    "            normalized_frame = self.preprocess_frame(frame)\n",
    "            frames_list.append(normalized_frame)\n",
    "\n",
    "            # Ensure we have enough frames for the sequence\n",
    "            if len(frames_list) == SEQUENCE_LENGTH:\n",
    "                # Perform prediction\n",
    "                predicted_labels_probabilities = self.model.predict(np.expand_dims(frames_list, axis=0))[0]\n",
    "                predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "                predicted_class_name = self.config.classes_list[predicted_label]\n",
    "\n",
    "                # Display the prediction\n",
    "                confidence = predicted_labels_probabilities[predicted_label]\n",
    "                print(f'Predicted: {predicted_class_name}\\nConfidence: {confidence}')\n",
    "\n",
    "                # Display \"Violence\" in red if confidence is above the threshold\n",
    "                if predicted_class_name == \"Violence\" and confidence > confidence_threshold:\n",
    "                    cv2.putText(frame, \"Violence\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    no_of_detections += 1\n",
    "\n",
    "                    if no_of_detections >= 7 and alert_sent == 0:\n",
    "                        current_time = self.get_time()\n",
    "                        self.img_enhance(frame)\n",
    "                        pixels = plt.imread(violence_image)\n",
    "                        detector = MTCNN()\n",
    "                        faces = detector.detect_faces(pixels)\n",
    "                        self.draw_faces(violence_image, faces)\n",
    "\n",
    "                        try:\n",
    "                            bot.sendMessage(self.CHAT_ID, f\"VIOLENCE ALERT!! \\n at location: {location} \\n time: {current_time}\")\n",
    "                            bot.sendPhoto(self.CHAT_ID, photo=open(os.path.join(self.config.root_dir,\"finalImage.jpg\"), 'rb'))\n",
    "                            bot.sendMessage(self.CHAT_ID, \"Faces Obtained\")\n",
    "                            bot.sendPhoto(self.CHAT_ID, photo=open(os.path.join(self.config.root_dir,\"faces.png\"), 'rb'))\n",
    "\n",
    "                            storage_client = storage.bucket()\n",
    "                            storage_client.blob(violence_image).upload_from_filename(violence_image)\n",
    "                            storage_client.blob(face_image).upload_from_filename(face_image)\n",
    "\n",
    "                            # Get download URLs for the uploaded images\n",
    "                            violence_image_url = storage_client.blob(violence_image).public_url\n",
    "                            face_image_url = storage_client.blob(face_image).public_url\n",
    "\n",
    "                            # Add data to Firestore with download URLs\n",
    "                            self.db.collection(location).add({\n",
    "                                'date': current_time,\n",
    "                                'image': violence_image_url,\n",
    "                                'faces': face_image_url\n",
    "                            })\n",
    "                            alert_sent = 1\n",
    "                            last_alert_time = time.time()\n",
    "\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error sending elert: {e}\")\n",
    "\n",
    "                        finally:\n",
    "                            pass\n",
    "\n",
    "                # Check if it's been 5 minutes since the last alert\n",
    "                if last_alert_time is not None and time.time() - last_alert_time >= 5 * 60:\n",
    "                    alert_sent = 0\n",
    "\n",
    "                # Clear the frames list for the next sequence\n",
    "                frames_list = []\n",
    "\n",
    "            # Display the webcam feed\n",
    "            cv2.imshow('Violence Detector', frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed        \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        # Release the webcam and close the window outside the loop\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    \n",
    "    def predict(self):\n",
    "        self.model = self.load_model(self.config.model_path)\n",
    "        self.set_credentials()\n",
    "        self.initialize_database()\n",
    "        self.predict_webcam()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-01 20:06:50,911: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-04-01 20:06:50,914: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-04-01 20:06:50,915: INFO: common: created directory at: artifacts]\n",
      "[2024-04-01 20:06:50,916: INFO: common: created directory at: artifacts\\alert_data]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted: NonViolence\n",
      "Confidence: 0.9982878565788269\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.9969821572303772\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.9951403141021729\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.990017831325531\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.9978844523429871\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.9994657635688782\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.9997127652168274\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicted: Violence\n",
      "Confidence: 0.9976781010627747\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "3/3 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Error sending elert: 'Prediction' object has no attribute 'db'\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicted: NonViolence\n",
      "Confidence: 0.9845259189605713\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predicted: NonViolence\n",
      "Confidence: 0.9861272573471069\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predicted: NonViolence\n",
      "Confidence: 0.9859201312065125\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicted: NonViolence\n",
      "Confidence: 0.9805441498756409\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config=ConfigurationManager()\n",
    "    pred_config=config.get_prediction_config()\n",
    "    prediction=Prediction(pred_config)\n",
    "    prediction.predict()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

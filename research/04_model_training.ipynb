{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ML_Projects\\\\Violence-Reporter'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    prediction_model_path: Path\n",
    "    model_checkpoints_path: Path\n",
    "    model_history: Path\n",
    "    model_evaluation_history: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_image_height: list\n",
    "    params_image_width: list\n",
    "    params_test_size: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from violenceReporter.constants import *\n",
    "from violenceReporter.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = self.config.data_transformation.root_dir\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            prediction_model_path= Path(training.prediction_model_path),\n",
    "            model_checkpoints_path= Path(training.model_checkpoints_path),\n",
    "            model_evaluation_history= Path(training.model_evaluation_history),\n",
    "            model_history= Path(training.model_history),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_image_height=params.IMAGE_HEIGHT,\n",
    "            params_image_width=params.IMAGE_WIDTH,\n",
    "            params_test_size=params.TEST_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = load_model(self.config.updated_base_model_path)\n",
    "\n",
    "    def train_test_generator(self):\n",
    "\n",
    "        features = np.load(os.path.join(self.config.training_data,\"features.npy\"))\n",
    "        labels= np.load(os.path.join(self.config.training_data,\"labels.npy\"))\n",
    "        video_files_paths = np.load(os.path.join(self.config.training_data,\"video_files_paths.npy\"))\n",
    "\n",
    "        one_hot_encoded_labels = to_categorical(labels)\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size=self.config.params_test_size,\n",
    "                                                                            shuffle=True, random_state=42)\n",
    "\n",
    "        return features_train, features_test, labels_train, labels_test\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_csv(path, data):\n",
    "        with open(path, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(data.keys())\n",
    "            writer.writerow(data.values())\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        features_train, features_test, labels_train, labels_test=self.train_test_generator()\n",
    "\n",
    "        early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=5, min_lr=0.00005, verbose=1)\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint(self.config.model_checkpoints_path, save_best_only=True)\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=[\"accuracy\"])\n",
    "\n",
    "        model_history = self.model.fit(\n",
    "            x=features_train, \n",
    "            y=labels_train, \n",
    "            epochs=self.config.params_epochs, \n",
    "            batch_size=self.config.params_batch_size, \n",
    "            shuffle=True, \n",
    "            validation_split=self.config.params_test_size, \n",
    "            callbacks=[early_stopping_callback, reduce_lr, model_checkpoint])\n",
    "        \n",
    "        model_evaluation_history = self.model.evaluate(features_test, labels_test)\n",
    "\n",
    "        self.save_model(self.config.trained_model_path,self.model)\n",
    "        self.save_model(self.config.prediction_model_path,self.model)\n",
    "        pd.DataFrame(model_history.history).to_csv(self.config.model_history, index=False)\n",
    "        pd.DataFrame(model_evaluation_history).to_csv(self.config.model_evaluation_history, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-31 18:48:27,563: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-03-31 18:48:27,565: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-03-31 18:48:27,566: INFO: common: created directory at: artifacts]\n",
      "[2024-03-31 18:48:27,567: INFO: common: created directory at: artifacts\\training]\n",
      "Epoch 1/50\n",
      "71/71 [==============================] - 11s 77ms/step - loss: 0.6965 - accuracy: 0.5326 - val_loss: 0.6838 - val_accuracy: 0.5079 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.6771 - accuracy: 0.5538 - val_loss: 0.6556 - val_accuracy: 0.7143 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.6348 - accuracy: 0.6596 - val_loss: 0.5738 - val_accuracy: 0.8413 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.5203 - accuracy: 0.7743 - val_loss: 0.3598 - val_accuracy: 0.9683 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.4060 - accuracy: 0.8342 - val_loss: 0.2396 - val_accuracy: 0.9524 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.3537 - accuracy: 0.8695 - val_loss: 0.1845 - val_accuracy: 0.9365 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.2870 - accuracy: 0.8889 - val_loss: 0.1402 - val_accuracy: 0.9524 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 4s 55ms/step - loss: 0.2061 - accuracy: 0.9312 - val_loss: 0.0961 - val_accuracy: 0.9683 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.1730 - accuracy: 0.9471 - val_loss: 0.1942 - val_accuracy: 0.9365 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.1358 - accuracy: 0.9559 - val_loss: 0.1883 - val_accuracy: 0.9365 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.1287 - accuracy: 0.9541 - val_loss: 0.2656 - val_accuracy: 0.8889 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "71/71 [==============================] - 4s 56ms/step - loss: 0.1652 - accuracy: 0.9489 - val_loss: 0.0698 - val_accuracy: 0.9841 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.1274 - accuracy: 0.9594 - val_loss: 0.1397 - val_accuracy: 0.9365 - lr: 0.0100\n",
      "Epoch 14/50\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.0539 - accuracy: 0.9894 - val_loss: 0.1323 - val_accuracy: 0.9524 - lr: 0.0100\n",
      "Epoch 15/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0862 - accuracy: 0.9753 - val_loss: 0.2251 - val_accuracy: 0.9206 - lr: 0.0100\n",
      "Epoch 16/50\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.1093 - accuracy: 0.9630 - val_loss: 0.0927 - val_accuracy: 0.9683 - lr: 0.0100\n",
      "Epoch 17/50\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.9696\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.005999999865889549.\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0826 - accuracy: 0.9700 - val_loss: 0.1312 - val_accuracy: 0.9524 - lr: 0.0100\n",
      "Epoch 18/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0774 - accuracy: 0.9824 - val_loss: 0.1178 - val_accuracy: 0.9524 - lr: 0.0060\n",
      "Epoch 19/50\n",
      "71/71 [==============================] - 4s 57ms/step - loss: 0.0530 - accuracy: 0.9877 - val_loss: 0.0065 - val_accuracy: 1.0000 - lr: 0.0060\n",
      "Epoch 20/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0457 - accuracy: 0.9929 - val_loss: 0.0113 - val_accuracy: 1.0000 - lr: 0.0060\n",
      "Epoch 21/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0741 - accuracy: 0.9859 - val_loss: 0.0704 - val_accuracy: 0.9683 - lr: 0.0060\n",
      "Epoch 22/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0859 - accuracy: 0.9718 - val_loss: 0.0455 - val_accuracy: 0.9683 - lr: 0.0060\n",
      "Epoch 23/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0597 - accuracy: 0.9806 - val_loss: 0.0505 - val_accuracy: 0.9683 - lr: 0.0060\n",
      "Epoch 24/50\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9911\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.003600000031292438.\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.0443 - accuracy: 0.9912 - val_loss: 0.0153 - val_accuracy: 1.0000 - lr: 0.0060\n",
      "Epoch 25/50\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.0224 - accuracy: 0.9982 - val_loss: 0.0370 - val_accuracy: 0.9841 - lr: 0.0036\n",
      "Epoch 26/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0571 - accuracy: 0.9894 - val_loss: 0.0727 - val_accuracy: 0.9683 - lr: 0.0036\n",
      "Epoch 27/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.0853 - val_accuracy: 0.9841 - lr: 0.0036\n",
      "Epoch 28/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0586 - accuracy: 0.9806 - val_loss: 0.0984 - val_accuracy: 0.9841 - lr: 0.0036\n",
      "Epoch 29/50\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9964\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0021599999628961085.\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.0201 - accuracy: 0.9965 - val_loss: 0.1196 - val_accuracy: 0.9683 - lr: 0.0036\n",
      "Epoch 30/50\n",
      "71/71 [==============================] - 4s 53ms/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 0.1372 - val_accuracy: 0.9683 - lr: 0.0022\n",
      "Epoch 31/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 0.1047 - val_accuracy: 0.9683 - lr: 0.0022\n",
      "Epoch 32/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0180 - accuracy: 0.9982 - val_loss: 0.0888 - val_accuracy: 0.9683 - lr: 0.0022\n",
      "Epoch 33/50\n",
      "71/71 [==============================] - 4s 52ms/step - loss: 0.0140 - accuracy: 0.9982 - val_loss: 0.0773 - val_accuracy: 0.9683 - lr: 0.0022\n",
      "Epoch 34/50\n",
      "70/71 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0012959999497979878.\n",
      "71/71 [==============================] - 4s 54ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9683 - lr: 0.0022\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.0543 - accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train()\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reporter",
   "language": "python",
   "name": "reporter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
